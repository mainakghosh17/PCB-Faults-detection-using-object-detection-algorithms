{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPq_ZL-wGeZ4",
        "collapsed": true,
        "outputId": "ad1c601f-83c4-444e-f262-00e422bdeff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement xml.etree.ElementTree (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for xml.etree.ElementTree\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers torch torchvision pycocotools xml.etree.ElementTree numpy scikit-learn matplotlib\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_paths = {\n",
        "    'Missing_hole': '/content/drive/My Drive/PCB/PCB_DATASET/images/Missing_hole',\n",
        "    'Mouse_bite': '/content/drive/My Drive/PCB/PCB_DATASET/images/Mouse_bite',\n",
        "    'Open_circuit': '/content/drive/My Drive/PCB/PCB_DATASET/images/Open_circuit',\n",
        "    'Short': '/content/drive/My Drive/PCB/PCB_DATASET/images/Short',\n",
        "    'Spurious_copper': '/content/drive/My Drive/PCB/PCB_DATASET/images/Spurious_copper',\n",
        "    'Spur': '/content/drive/My Drive/PCB/PCB_DATASET/images/Spur'\n",
        "}\n",
        "\n",
        "annotation_paths = {\n",
        "    'Missing_hole': '/content/drive/My Drive/PCB/PCB_DATASET/Annotations/Missing_hole',\n",
        "    'Mouse_bite': '/content/drive/My Drive/PCB/PCB_DATASET/Annotations/Mouse_bite',\n",
        "    'Open_circuit': '/content/drive/My Drive/PCB/PCB_DATASET/Annotations/Open_circuit',\n",
        "    'Short': '/content/drive/My Drive/PCB/PCB_DATASET/Annotations/Short',\n",
        "    'Spurious_copper': '/content/drive/My Drive/PCB/PCB_DATASET/Annotations/Spurious_copper',\n",
        "    'Spur': '/content/drive/My Drive/PCB/PCB_DATASET/Annotations/Spur'\n",
        "}\n",
        "\n",
        "# Define classes\n",
        "CLASSES = ['Missing Hole', 'Open Circuit', 'Short Circuit', 'Spur', 'Spurious Copper', 'Mouse Bite']\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "id2label = {i: label for i, label in enumerate(CLASSES)}\n",
        "label2id = {label: i for i, label in enumerate(CLASSES)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVrn4CZiwws9",
        "outputId": "e08dfa5d-e155-432b-d2af-92f5ff95a973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset\n",
        "class PCBDataset(Dataset):\n",
        "    def __init__(self, data_paths, annotation_paths, processor):\n",
        "        self.data_paths = data_paths\n",
        "        self.annotation_paths = annotation_paths\n",
        "        self.processor = processor\n",
        "        self.images = []\n",
        "        self.annotations = []\n",
        "\n",
        "        for defect_type in data_paths.keys():\n",
        "            img_path = data_paths[defect_type]\n",
        "            ann_path = annotation_paths[defect_type]\n",
        "\n",
        "            for img_file in os.listdir(img_path):\n",
        "                if img_file.endswith(('.jpg', '.png')):\n",
        "                    img_id = len(self.images)\n",
        "                    xml_file = os.path.join(ann_path, img_file.replace('.jpg', '.xml').replace('.png', '.xml'))\n",
        "\n",
        "                    if os.path.exists(xml_file):\n",
        "                        self.images.append(os.path.join(img_path, img_file))\n",
        "                        self.annotations.append(self.parse_voc_xml(xml_file, img_id))\n",
        "\n",
        "    def parse_voc_xml(self, xml_file, img_id):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        annotations = []\n",
        "        for obj in root.findall('object'):\n",
        "            name = obj.find('name').text\n",
        "            if name in label2id:\n",
        "                bbox = obj.find('bndbox')\n",
        "                annotations.append({\n",
        "                    'image_id': img_id,\n",
        "                    'category_id': label2id[name],\n",
        "                    'bbox': [\n",
        "                        float(bbox.find('xmin').text),\n",
        "                        float(bbox.find('ymin').text),\n",
        "                        float(bbox.find('xmax').text) - float(bbox.find('xmin').text),\n",
        "                        float(bbox.find('ymax').text) - float(bbox.find('ymin').text)\n",
        "                    ],\n",
        "                    'area': (float(bbox.find('xmax').text) - float(bbox.find('xmin').text)) *\n",
        "                            (float(bbox.find('ymax').text) - float(bbox.find('ymin').text)),\n",
        "                    'iscrowd': 0\n",
        "                })\n",
        "        return annotations\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        annotations = self.annotations[idx]  # List of annotation dicts from parse_voc_xml\n",
        "\n",
        "        # Process image and annotations with DETR processor\n",
        "        encoding = self.processor(\n",
        "            images=image,\n",
        "            annotations={'image_id': idx, 'annotations': annotations},\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Ensure pixel_values and pixel_mask have correct shape (remove extra dim)\n",
        "        pixel_values = encoding['pixel_values'].squeeze(0)  # Remove batch dim [1, 3, H, W] -> [3, H, W]\n",
        "        pixel_mask = encoding['pixel_mask'].squeeze(0)      # Remove batch dim [1, H, W] -> [H, W]\n",
        "\n",
        "        # Format labels as a single dict per image\n",
        "        labels_dict = {\n",
        "            'labels': encoding['labels'],  # Tensor of class IDs\n",
        "            'boxes': encoding['boxes']     # Tensor of box coordinates\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            'pixel_values': pixel_values,\n",
        "            'pixel_mask': pixel_mask,\n",
        "            'labels': labels_dict\n",
        "        }\n",
        "\n",
        "# The processor and dataset remain the same\n",
        "# Update processor initialization (fix max_size warning)\n",
        "processor = DetrImageProcessor.from_pretrained(\n",
        "    'facebook/detr-resnet-50',\n",
        "    size={'shortest_edge': 800, 'longest_edge': 1333}\n",
        ")"
      ],
      "metadata": {
        "id": "0yP4ZA9yw1vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset and dataloader\n",
        "def custom_collate_fn(batch):\n",
        "    pixel_values = [item['pixel_values'] for item in batch]\n",
        "    pixel_mask = [item['pixel_mask'] for item in batch]\n",
        "    labels = [item['labels'] for item in batch]\n",
        "\n",
        "    # Pad images to the largest size in the batch\n",
        "    max_height = max(pv.shape[-2] for pv in pixel_values)\n",
        "    max_width = max(pv.shape[-1] for pv in pixel_values)\n",
        "\n",
        "    pixel_values_padded = torch.stack([\n",
        "        torch.nn.functional.pad(pv, (0, max_width - pv.shape[-1], 0, max_height - pv.shape[-2]))\n",
        "        for pv in pixel_values\n",
        "    ])\n",
        "\n",
        "    pixel_mask_padded = torch.stack([\n",
        "        torch.nn.functional.pad(pm, (0, max_width - pm.shape[-1], 0, max_height - pm.shape[-2]))\n",
        "        for pm in pixel_mask\n",
        "    ])\n",
        "\n",
        "    return {\n",
        "        'pixel_values': pixel_values_padded,\n",
        "        'pixel_mask': pixel_mask_padded,\n",
        "        'labels': labels\n",
        "    }\n",
        "dataset = PCBDataset(data_paths, annotation_paths, processor)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    collate_fn=custom_collate_fn\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    collate_fn=custom_collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "Fb2Y4yJQw5Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DetrForObjectDetection.from_pretrained('facebook/detr-resnet-50', num_labels=NUM_CLASSES, ignore_mismatched_sizes=True)\n",
        "model.to('cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "03WRMKLEw67W",
        "outputId": "82487835-d0ad-41af-f945-a2cedd94f812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized because the shapes did not match:\n",
            "- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
            "- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([7, 256]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DetrForObjectDetection(\n",
              "  (model): DetrModel(\n",
              "    (backbone): DetrConvModel(\n",
              "      (conv_encoder): DetrConvEncoder(\n",
              "        (model): FeatureListNet(\n",
              "          (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "          (bn1): DetrFrozenBatchNorm2d()\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "          (layer1): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "              (downsample): Sequential(\n",
              "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (1): DetrFrozenBatchNorm2d()\n",
              "              )\n",
              "            )\n",
              "            (1): Bottleneck(\n",
              "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "            )\n",
              "            (2): Bottleneck(\n",
              "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "          (layer2): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "              (downsample): Sequential(\n",
              "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (1): DetrFrozenBatchNorm2d()\n",
              "              )\n",
              "            )\n",
              "            (1): Bottleneck(\n",
              "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "            )\n",
              "            (2): Bottleneck(\n",
              "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "            )\n",
              "            (3): Bottleneck(\n",
              "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "          (layer3): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "              (downsample): Sequential(\n",
              "                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (1): DetrFrozenBatchNorm2d()\n",
              "              )\n",
              "            )\n",
              "            (1): Bottleneck(\n",
              "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "            )\n",
              "            (2): Bottleneck(\n",
              "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "            )\n",
              "            (3): Bottleneck(\n",
              "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "            )\n",
              "            (4): Bottleneck(\n",
              "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "            )\n",
              "            (5): Bottleneck(\n",
              "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "          (layer4): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "              (downsample): Sequential(\n",
              "                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (1): DetrFrozenBatchNorm2d()\n",
              "              )\n",
              "            )\n",
              "            (1): Bottleneck(\n",
              "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "            )\n",
              "            (2): Bottleneck(\n",
              "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn1): DetrFrozenBatchNorm2d()\n",
              "              (act1): ReLU(inplace=True)\n",
              "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn2): DetrFrozenBatchNorm2d()\n",
              "              (drop_block): Identity()\n",
              "              (act2): ReLU(inplace=True)\n",
              "              (aa): Identity()\n",
              "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn3): DetrFrozenBatchNorm2d()\n",
              "              (act3): ReLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (position_embedding): DetrSinePositionEmbedding()\n",
              "    )\n",
              "    (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (query_position_embeddings): Embedding(100, 256)\n",
              "    (encoder): DetrEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x DetrEncoderLayer(\n",
              "          (self_attn): DetrAttention(\n",
              "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): ReLU()\n",
              "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): DetrDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x DetrDecoderLayer(\n",
              "          (self_attn): DetrAttention(\n",
              "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (activation_fn): ReLU()\n",
              "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): DetrAttention(\n",
              "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (class_labels_classifier): Linear(in_features=256, out_features=7, bias=True)\n",
              "  (bbox_predictor): DetrMLPPredictionHead(\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
              "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified training loop (adjusted for correct label access)\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        pixel_values = batch['pixel_values']  # Shape should be [batch_size, 3, H, W]\n",
        "        pixel_mask = batch['pixel_mask']      # Shape should be [batch_size, H, W]\n",
        "        labels = batch['labels']              # List of dicts\n",
        "\n",
        "        # Debug prints\n",
        "        print(\"Pixel values shape:\", pixel_values.shape)\n",
        "        print(\"Pixel mask shape:\", pixel_mask.shape)\n",
        "        print(\"Labels type:\", type(labels))\n",
        "        print(\"First label type:\", type(labels[0]))\n",
        "        print(\"First label keys:\", labels[0].keys())\n",
        "\n",
        "        # Ensure labels are in the correct format (list of dicts)\n",
        "        formatted_labels = []\n",
        "        for label in labels:\n",
        "            if isinstance(label, dict) and 'labels' in label and 'boxes' in label:\n",
        "                formatted_labels.append(label)\n",
        "            else:\n",
        "                raise ValueError(f\"Unexpected label format in training: {type(label)}\")\n",
        "\n",
        "        labels = formatted_labels\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(\n",
        "            pixel_values=pixel_values,\n",
        "            pixel_mask=pixel_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_dataloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "Xv4Toi8-w-8C",
        "outputId": "7d3ed63f-4e23-4d77-afe5-4570286755d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n",
            "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"<ipython-input-33-9a88df9da7ea>\", line 69, in __getitem__\n    'boxes': encoding['boxes']     # Tensor of box coordinates\n             ~~~~~~~~^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/feature_extraction_utils.py\", line 87, in __getitem__\n    return self.data[item]\n           ~~~~~~~~~^^^^^^\nKeyError: 'boxes'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-28c185a10140>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mpixel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixel_values'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Shape should be [batch_size, 3, H, W]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpixel_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixel_mask'\u001b[0m\u001b[0;34m]\u001b[0m      \u001b[0;31m# Shape should be [batch_size, H, W]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"<ipython-input-33-9a88df9da7ea>\", line 69, in __getitem__\n    'boxes': encoding['boxes']     # Tensor of box coordinates\n             ~~~~~~~~^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/feature_extraction_utils.py\", line 87, in __getitem__\n    return self.data[item]\n           ~~~~~~~~~^^^^^^\nKeyError: 'boxes'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            pixel_values = batch['pixel_values'].to('cuda')\n",
        "            outputs = model(pixel_values=pixel_values)\n",
        "\n",
        "            pred_boxes = outputs.pred_boxes.cpu().numpy()\n",
        "            pred_scores = outputs.logits.softmax(-1).cpu().numpy()\n",
        "            true_labels = [label['labels'].cpu().numpy() for label in batch['labels']]\n",
        "\n",
        "            for i in range(len(pred_boxes)):\n",
        "                pred = pred_scores[i].argmax(-1)\n",
        "                all_preds.extend(pred)\n",
        "                all_labels.extend(true_labels[i])\n",
        "\n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    precision = np.diag(cm) / np.sum(cm, axis=0)\n",
        "    recall = np.diag(cm) / np.sum(cm, axis=1)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    mAP = np.mean([p for p in precision if not np.isnan(p)])  # Simple mAP approximation\n",
        "\n",
        "    print(f\"mAP: {mAP:.4f}\")\n",
        "    print(f\"Precision: {np.nanmean(precision):.4f}\")\n",
        "    print(f\"Recall: {np.nanmean(recall):.4f}\")\n",
        "    print(f\"F1 Score: {np.nanmean(f1):.4f}\")\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    return mAP\n",
        "\n",
        "# Evaluate the model\n",
        "mAP = evaluate(model, val_dataloader)"
      ],
      "metadata": {
        "id": "o-j7FqZcw_4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive/PCB/detr_pcb_model.pth')"
      ],
      "metadata": {
        "id": "fveiUA7dxGlc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}